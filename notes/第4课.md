# 书生浦语大模型实战营--第四课

## 微调（Finetune）

微调常用的两种模式：增量预训练，指令微调

- 增量预训练：使用场景：让模型学习新知识，比如垂类领域的常识，训练数据使用文章，书籍，代码等
- 指令跟随微调：让模型学会对话模板，根据人类指定对话。训练数据：高质量的对话，问答数据。

## 指令跟随微调

> 指令跟随微调是为了能够得到实际对话的模型。

将数据使用对话模板构建为不同的角色对话（一问一答的数据），让模型学习。

对话场景下，通常有三个角色

- System：给定一些上下文信息，比如“你是一个安全的 AI助手”

- User：实际用户，会提出一些问题，比如“世界第一高峰是?”

- Assistant：根据 User 的输入，结合 System 的上下文信息，做出回答，比如“珠穆朗玛峰”

对话模板：对话模板是为了能够让 LLM 区分出，System、User 和 Assistant不同的模型会有不同的模板

不同于增量预训练微调，数据中会有Input 和 Output希望模型学会的是答案(Output)，而不是问题(Input)训练时只会对答案(Output)部分计算 Loss

## 增量预训练微调

> 增量预训练不需要使用一问一答的数据，他的训练数据只有对事实的陈述

训练时只需要把数据放入assitant角色中，system，user中的数据留空。

### LoRA&QLoRA

LoRA:LOW-RANK ADAPTATION OF LARGE LANGUAGE MODELS

>  LLM 的参数量主要集中在模型中的 Linear，训练这些参数会耗费大量的显存。LORA 通过在原本的 Linear 旁，新增一个支路，包含两个连续的小 Linear,新增的这个支路通常叫做 Adapter。Adapter 参数量远小于原本的 Linear，能大幅降低训练的显存消耗

Full Finetuning(No Adapters)

- 需要把整个模型加载到显存，所有模型参数优化器也需要加载到显存

LoRA

- 模型加载到显存，参数优化器只把LoRA部分的参数优化器加载到显存，这就大大减小了内存

QLoRA

- 使用4-bit量化加载模型，优化器在CPU和GPU间进行调度

